{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 1\n",
    "___\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn.\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random state должен быть равен 42.\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предсказаний с помощью r2_score из модуля sklearn.metrics.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonsineev/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston_data = load_boston()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_data.keys()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      "dtypes: float64(13)\n",
      "memory usage: 51.5 KB\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame(boston_data[\"data\"], columns=boston_data[\"feature_names\"])\n",
    "X.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   price   506 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 4.1 KB\n"
     ]
    }
   ],
   "source": [
    "Y = pd.DataFrame(boston_data[\"target\"], columns=[\"price\"])\n",
    "Y.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression()"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, Y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "y_predicts = lr.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "     y_test     y_pred\n24     15.6  15.466213\n351    24.1  21.073800\n434    11.7  15.278265\n131    19.6  20.231694\n395    13.1  20.363620\n124    18.8  20.277339\n485    21.2  22.992821\n69     20.9  21.198574\n22     15.2  15.604450\n42     25.3  25.817921",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_test</th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>24</th>\n      <td>15.6</td>\n      <td>15.466213</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>24.1</td>\n      <td>21.073800</td>\n    </tr>\n    <tr>\n      <th>434</th>\n      <td>11.7</td>\n      <td>15.278265</td>\n    </tr>\n    <tr>\n      <th>131</th>\n      <td>19.6</td>\n      <td>20.231694</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>13.1</td>\n      <td>20.363620</td>\n    </tr>\n    <tr>\n      <th>124</th>\n      <td>18.8</td>\n      <td>20.277339</td>\n    </tr>\n    <tr>\n      <th>485</th>\n      <td>21.2</td>\n      <td>22.992821</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>20.9</td>\n      <td>21.198574</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>15.2</td>\n      <td>15.604450</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>25.3</td>\n      <td>25.817921</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data = pd.DataFrame({ \"y_test\": Y_test[\"price\"], \"y_pred\": y_predicts.flatten()})\n",
    "check_data.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "     y_test     y_pred     error\n78     21.2  21.801723  0.601723\n176    23.2  25.572974  2.372974\n245    18.5  12.917294 -5.582706\n432    16.1  21.079536  4.979536\n82     24.8  26.156159  1.356159\n268    43.5  39.316136 -4.183864\n17     17.5  16.862428 -0.637572\n227    31.6  32.186088  0.586088\n2      34.7  30.949930 -3.750070\n101    26.5  26.112476 -0.387524",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_test</th>\n      <th>y_pred</th>\n      <th>error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>78</th>\n      <td>21.2</td>\n      <td>21.801723</td>\n      <td>0.601723</td>\n    </tr>\n    <tr>\n      <th>176</th>\n      <td>23.2</td>\n      <td>25.572974</td>\n      <td>2.372974</td>\n    </tr>\n    <tr>\n      <th>245</th>\n      <td>18.5</td>\n      <td>12.917294</td>\n      <td>-5.582706</td>\n    </tr>\n    <tr>\n      <th>432</th>\n      <td>16.1</td>\n      <td>21.079536</td>\n      <td>4.979536</td>\n    </tr>\n    <tr>\n      <th>82</th>\n      <td>24.8</td>\n      <td>26.156159</td>\n      <td>1.356159</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>43.5</td>\n      <td>39.316136</td>\n      <td>-4.183864</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>17.5</td>\n      <td>16.862428</td>\n      <td>-0.637572</td>\n    </tr>\n    <tr>\n      <th>227</th>\n      <td>31.6</td>\n      <td>32.186088</td>\n      <td>0.586088</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34.7</td>\n      <td>30.949930</td>\n      <td>-3.750070</td>\n    </tr>\n    <tr>\n      <th>101</th>\n      <td>26.5</td>\n      <td>26.112476</td>\n      <td>-0.387524</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[\"error\"] = check_data[\"y_pred\"] - check_data[\"y_test\"]\n",
    "check_data.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6693702691495609"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_LR=r2_score(check_data[\"y_pred\"], check_data[\"y_test\"])\n",
    "r2_score_LR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 2\n",
    "___\n",
    "Создайте модель под названием model с помощью #из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000,\n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression,\n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(max_depth=12, n_estimators=1000, random_state=42)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train.values[:, 0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "RFC_predict = model.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "     y_test     y_pred\n442    18.4  15.852103\n195    50.0  45.947700\n172    23.1  19.699501\n33     13.1  15.768559\n437     8.7   9.000083\n307    28.2  29.577651\n325    24.6  24.830664\n447    12.6  16.072425\n15     19.9  20.215972\n448    14.1  15.501419",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>y_test</th>\n      <th>y_pred</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>442</th>\n      <td>18.4</td>\n      <td>15.852103</td>\n    </tr>\n    <tr>\n      <th>195</th>\n      <td>50.0</td>\n      <td>45.947700</td>\n    </tr>\n    <tr>\n      <th>172</th>\n      <td>23.1</td>\n      <td>19.699501</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>13.1</td>\n      <td>15.768559</td>\n    </tr>\n    <tr>\n      <th>437</th>\n      <td>8.7</td>\n      <td>9.000083</td>\n    </tr>\n    <tr>\n      <th>307</th>\n      <td>28.2</td>\n      <td>29.577651</td>\n    </tr>\n    <tr>\n      <th>325</th>\n      <td>24.6</td>\n      <td>24.830664</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>12.6</td>\n      <td>16.072425</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>19.9</td>\n      <td>20.215972</td>\n    </tr>\n    <tr>\n      <th>448</th>\n      <td>14.1</td>\n      <td>15.501419</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_RFC = pd.DataFrame({ \"y_test\": Y_test[\"price\"], \"y_pred\": RFC_predict.flatten()})\n",
    "check_RFC.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8479049999699443"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_RFC=r2_score(check_RFC[\"y_pred\"], check_RFC[\"y_test\"])\n",
    "r2_score_RFC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score_LR < r2_score_RFC"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RFC (RandomForestClassifier) - лучше."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 3\n",
    "___\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности,\n",
    "установите, какие два признака показывают наибольшую важность.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "?RandomForestRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "feature_importances_ : ndarray of shape (n_features,)\n",
    "    The impurity-based feature importances.\n",
    "    The higher, the more important the feature.\n",
    "    The importance of a feature is computed as the (normalized)\n",
    "    total reduction of the criterion brought by that feature.  It is also\n",
    "    known as the Gini importance.\n",
    "\n",
    "    Warning: impurity-based feature importances can be misleading for\n",
    "    high cardinality features (many unique values). See\n",
    "    :func:`sklearn.inspection.permutation_importance` as an alternative."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03167574 0.00154252 0.00713813 0.00123624 0.01426897 0.40268179\n",
      " 0.01429864 0.06397257 0.00528122 0.01152493 0.01808108 0.01245085\n",
      " 0.41584732]\n"
     ]
    }
   ],
   "source": [
    "print(model.feature_importances_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "1.0"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model.feature_importances_.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/antonsineev/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `n_features_` was deprecated in version 1.0 and will be removed in 1.2. Use `n_features_in_` instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index:  12  - value: 0.4158473181914483\n",
      "index:  5  - value: 0.4026817857034993\n"
     ]
    }
   ],
   "source": [
    "firstImportance = [model.feature_importances_.argmax(), model.feature_importances_.max()]\n",
    "tempMax = model.feature_importances_[0]\n",
    "for i in range(model.n_features_):\n",
    "    if tempMax < model.feature_importances_[i] and i != firstImportance[0]:\n",
    "        tempMax = model.feature_importances_[i]\n",
    "        index = i\n",
    "secondImportance = [index, tempMax]\n",
    "print('index: ',firstImportance[0], ' - value:', firstImportance[1])\n",
    "print('index: ',secondImportance[0], ' - value:', secondImportance[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Задание 4\n",
    "___\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована. Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "data": {
      "text/plain": "            Time        V1        V2        V3        V4        V5        V6  \\\n33400    37218.0  0.881348 -1.092078  1.135444  0.559197 -1.180711  1.152884   \n269343  163632.0  1.978709 -0.256250 -0.382319  0.144798 -0.437336 -0.320076   \n111721   72341.0  1.202552  0.151627  0.242359  0.731186 -0.541596 -1.101685   \n199527  133005.0  2.043163  0.237765 -1.586782  1.387635  0.411525 -1.158497   \n51433    44942.0 -4.376483 -3.704106  1.187411  0.203134  3.596434 -0.610099   \n135710   81368.0 -1.395528  1.587455  0.680140  1.267192 -0.673379  0.146225   \n56693    47540.0 -0.415985  1.071116  1.660502  0.392653  0.289936 -0.808320   \n165044  117163.0  0.136655  1.022349 -1.061493  0.020518  0.126995 -1.404338   \n230886  146522.0  2.039733  0.186370 -1.482762  0.536745  0.179863 -1.172539   \n233089  147435.0  2.041950  0.214264 -2.029746  0.483306  0.593165 -1.084873   \n\n              V7        V8        V9  ...       V21       V22       V23  \\\n33400  -1.062757  0.468625 -0.435857  ... -0.238090 -0.274987  0.010908   \n269343 -0.504501  0.022329  0.981566  ... -0.079941 -0.089551  0.293454   \n111721  0.014241 -0.119951  0.271721  ... -0.289519 -0.975377  0.124617   \n199527  0.617411 -0.403573  0.240388  ...  0.042479  0.357911  0.007859   \n51433  -2.194108  1.440114 -0.567951  ...  0.309771 -0.838009 -0.022602   \n135710 -0.218118  1.144904 -0.574173  ...  0.065960  0.298761 -0.029115   \n56693   0.923711 -0.430002 -0.604140  ... -0.212915 -0.469399 -0.082290   \n165044  0.690330  0.114097 -0.112538  ...  0.346219  0.913291  0.004055   \n230886  0.207746 -0.279369  0.432415  ... -0.328997 -0.835193  0.401906   \n233089  0.435273 -0.351347  0.278067  ... -0.222486 -0.539809  0.203728   \n\n             V24       V25       V26       V27       V28  Amount  Class  \n33400  -0.327375  0.076739 -0.378907  0.102938  0.048619  140.10      0  \n269343 -0.376177 -0.330982 -0.926095  0.059762 -0.038835    1.00      0  \n111721  0.302927  0.151906  0.096867 -0.038680  0.032123   28.99      0  \n199527 -0.014873  0.452428 -0.487827 -0.014848 -0.063879    1.00      0  \n51433  -1.361577 -0.253874  0.180096 -0.006307 -0.709867    7.00      0  \n135710  0.208144 -0.084360 -0.240069  0.296469  0.109751   24.74      0  \n56693   0.375185 -0.389129  0.106844 -0.204561 -0.076695    9.99      0  \n165044 -0.038964 -0.268568 -0.152350 -0.084450 -0.044713   47.97      0  \n230886  1.056827 -0.320904  0.139135 -0.060797 -0.024930    1.29      0  \n233089  0.662299 -0.045710  0.328619 -0.075504 -0.028278   24.36      0  \n\n[10 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>33400</th>\n      <td>37218.0</td>\n      <td>0.881348</td>\n      <td>-1.092078</td>\n      <td>1.135444</td>\n      <td>0.559197</td>\n      <td>-1.180711</td>\n      <td>1.152884</td>\n      <td>-1.062757</td>\n      <td>0.468625</td>\n      <td>-0.435857</td>\n      <td>...</td>\n      <td>-0.238090</td>\n      <td>-0.274987</td>\n      <td>0.010908</td>\n      <td>-0.327375</td>\n      <td>0.076739</td>\n      <td>-0.378907</td>\n      <td>0.102938</td>\n      <td>0.048619</td>\n      <td>140.10</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>269343</th>\n      <td>163632.0</td>\n      <td>1.978709</td>\n      <td>-0.256250</td>\n      <td>-0.382319</td>\n      <td>0.144798</td>\n      <td>-0.437336</td>\n      <td>-0.320076</td>\n      <td>-0.504501</td>\n      <td>0.022329</td>\n      <td>0.981566</td>\n      <td>...</td>\n      <td>-0.079941</td>\n      <td>-0.089551</td>\n      <td>0.293454</td>\n      <td>-0.376177</td>\n      <td>-0.330982</td>\n      <td>-0.926095</td>\n      <td>0.059762</td>\n      <td>-0.038835</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>111721</th>\n      <td>72341.0</td>\n      <td>1.202552</td>\n      <td>0.151627</td>\n      <td>0.242359</td>\n      <td>0.731186</td>\n      <td>-0.541596</td>\n      <td>-1.101685</td>\n      <td>0.014241</td>\n      <td>-0.119951</td>\n      <td>0.271721</td>\n      <td>...</td>\n      <td>-0.289519</td>\n      <td>-0.975377</td>\n      <td>0.124617</td>\n      <td>0.302927</td>\n      <td>0.151906</td>\n      <td>0.096867</td>\n      <td>-0.038680</td>\n      <td>0.032123</td>\n      <td>28.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>199527</th>\n      <td>133005.0</td>\n      <td>2.043163</td>\n      <td>0.237765</td>\n      <td>-1.586782</td>\n      <td>1.387635</td>\n      <td>0.411525</td>\n      <td>-1.158497</td>\n      <td>0.617411</td>\n      <td>-0.403573</td>\n      <td>0.240388</td>\n      <td>...</td>\n      <td>0.042479</td>\n      <td>0.357911</td>\n      <td>0.007859</td>\n      <td>-0.014873</td>\n      <td>0.452428</td>\n      <td>-0.487827</td>\n      <td>-0.014848</td>\n      <td>-0.063879</td>\n      <td>1.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>51433</th>\n      <td>44942.0</td>\n      <td>-4.376483</td>\n      <td>-3.704106</td>\n      <td>1.187411</td>\n      <td>0.203134</td>\n      <td>3.596434</td>\n      <td>-0.610099</td>\n      <td>-2.194108</td>\n      <td>1.440114</td>\n      <td>-0.567951</td>\n      <td>...</td>\n      <td>0.309771</td>\n      <td>-0.838009</td>\n      <td>-0.022602</td>\n      <td>-1.361577</td>\n      <td>-0.253874</td>\n      <td>0.180096</td>\n      <td>-0.006307</td>\n      <td>-0.709867</td>\n      <td>7.00</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>135710</th>\n      <td>81368.0</td>\n      <td>-1.395528</td>\n      <td>1.587455</td>\n      <td>0.680140</td>\n      <td>1.267192</td>\n      <td>-0.673379</td>\n      <td>0.146225</td>\n      <td>-0.218118</td>\n      <td>1.144904</td>\n      <td>-0.574173</td>\n      <td>...</td>\n      <td>0.065960</td>\n      <td>0.298761</td>\n      <td>-0.029115</td>\n      <td>0.208144</td>\n      <td>-0.084360</td>\n      <td>-0.240069</td>\n      <td>0.296469</td>\n      <td>0.109751</td>\n      <td>24.74</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>56693</th>\n      <td>47540.0</td>\n      <td>-0.415985</td>\n      <td>1.071116</td>\n      <td>1.660502</td>\n      <td>0.392653</td>\n      <td>0.289936</td>\n      <td>-0.808320</td>\n      <td>0.923711</td>\n      <td>-0.430002</td>\n      <td>-0.604140</td>\n      <td>...</td>\n      <td>-0.212915</td>\n      <td>-0.469399</td>\n      <td>-0.082290</td>\n      <td>0.375185</td>\n      <td>-0.389129</td>\n      <td>0.106844</td>\n      <td>-0.204561</td>\n      <td>-0.076695</td>\n      <td>9.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>165044</th>\n      <td>117163.0</td>\n      <td>0.136655</td>\n      <td>1.022349</td>\n      <td>-1.061493</td>\n      <td>0.020518</td>\n      <td>0.126995</td>\n      <td>-1.404338</td>\n      <td>0.690330</td>\n      <td>0.114097</td>\n      <td>-0.112538</td>\n      <td>...</td>\n      <td>0.346219</td>\n      <td>0.913291</td>\n      <td>0.004055</td>\n      <td>-0.038964</td>\n      <td>-0.268568</td>\n      <td>-0.152350</td>\n      <td>-0.084450</td>\n      <td>-0.044713</td>\n      <td>47.97</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>230886</th>\n      <td>146522.0</td>\n      <td>2.039733</td>\n      <td>0.186370</td>\n      <td>-1.482762</td>\n      <td>0.536745</td>\n      <td>0.179863</td>\n      <td>-1.172539</td>\n      <td>0.207746</td>\n      <td>-0.279369</td>\n      <td>0.432415</td>\n      <td>...</td>\n      <td>-0.328997</td>\n      <td>-0.835193</td>\n      <td>0.401906</td>\n      <td>1.056827</td>\n      <td>-0.320904</td>\n      <td>0.139135</td>\n      <td>-0.060797</td>\n      <td>-0.024930</td>\n      <td>1.29</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>233089</th>\n      <td>147435.0</td>\n      <td>2.041950</td>\n      <td>0.214264</td>\n      <td>-2.029746</td>\n      <td>0.483306</td>\n      <td>0.593165</td>\n      <td>-1.084873</td>\n      <td>0.435273</td>\n      <td>-0.351347</td>\n      <td>0.278067</td>\n      <td>...</td>\n      <td>-0.222486</td>\n      <td>-0.539809</td>\n      <td>0.203728</td>\n      <td>0.662299</td>\n      <td>-0.045710</td>\n      <td>0.328619</td>\n      <td>-0.075504</td>\n      <td>-0.028278</td>\n      <td>24.36</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.998273\n1    0.001727\nName: Class, dtype: float64"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Class\"].value_counts(normalize=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n5   2.0 -0.425966  0.960523  1.141109 -0.168252  0.420987 -0.029728  0.476201   \n6   4.0  1.229658  0.141004  0.045371  1.202613  0.191881  0.272708 -0.005159   \n7   7.0 -0.644269  1.417964  1.074380 -0.492199  0.948934  0.428118  1.120631   \n8   7.0 -0.894286  0.286157 -0.113192 -0.271526  2.669599  3.721818  0.370145   \n9   9.0 -0.338262  1.119593  1.044367 -0.222187  0.499361 -0.246761  0.651583   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n5  0.260314 -0.568671 -0.371407  1.341262  0.359894 -0.358091 -0.137134   \n6  0.081213  0.464960 -0.099254 -1.416907 -0.153826 -0.751063  0.167372   \n7 -3.807864  0.615375  1.249376 -0.619468  0.291474  1.757964 -1.323865   \n8  0.851084 -0.392048 -0.410430 -0.705117 -0.110452 -0.286254  0.074355   \n9  0.069539 -0.736727 -0.366846  1.017614  0.836390  1.006844 -0.443523   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n5  0.517617  0.401726 -0.058133  0.068653 -0.033194  0.084968 -0.208254   \n6  0.050144 -0.443587  0.002821 -0.611987 -0.045575 -0.219633 -0.167716   \n7  0.686133 -0.076127 -1.222127 -0.358222  0.324505 -0.156742  1.943465   \n8 -0.328783 -0.210077 -0.499768  0.118765  0.570328  0.052736 -0.073425   \n9  0.150219  0.739453 -0.540980  0.476677  0.451773  0.203711 -0.246914   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n5 -0.559825 -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080   \n6 -0.270710 -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168   \n7 -1.015455  0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   \n8 -0.268092 -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   \n9 -0.633753 -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076   \n\n   Amount  Class  \n0  149.62      0  \n1    2.69      0  \n2  378.66      0  \n3  123.50      0  \n4   69.99      0  \n5    3.67      0  \n6    4.99      0  \n7   40.80      0  \n8   93.20      0  \n9    3.68      0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>-0.551600</td>\n      <td>-0.617801</td>\n      <td>-0.991390</td>\n      <td>-0.311169</td>\n      <td>1.468177</td>\n      <td>-0.470401</td>\n      <td>0.207971</td>\n      <td>0.025791</td>\n      <td>0.403993</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>1.612727</td>\n      <td>1.065235</td>\n      <td>0.489095</td>\n      <td>-0.143772</td>\n      <td>0.635558</td>\n      <td>0.463917</td>\n      <td>-0.114805</td>\n      <td>-0.183361</td>\n      <td>-0.145783</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>0.624501</td>\n      <td>0.066084</td>\n      <td>0.717293</td>\n      <td>-0.165946</td>\n      <td>2.345865</td>\n      <td>-2.890083</td>\n      <td>1.109969</td>\n      <td>-0.121359</td>\n      <td>-2.261857</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>-0.226487</td>\n      <td>0.178228</td>\n      <td>0.507757</td>\n      <td>-0.287924</td>\n      <td>-0.631418</td>\n      <td>-1.059647</td>\n      <td>-0.684093</td>\n      <td>1.965775</td>\n      <td>-1.232622</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>-0.822843</td>\n      <td>0.538196</td>\n      <td>1.345852</td>\n      <td>-1.119670</td>\n      <td>0.175121</td>\n      <td>-0.451449</td>\n      <td>-0.237033</td>\n      <td>-0.038195</td>\n      <td>0.803487</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2.0</td>\n      <td>-0.425966</td>\n      <td>0.960523</td>\n      <td>1.141109</td>\n      <td>-0.168252</td>\n      <td>0.420987</td>\n      <td>-0.029728</td>\n      <td>0.476201</td>\n      <td>0.260314</td>\n      <td>-0.568671</td>\n      <td>-0.371407</td>\n      <td>1.341262</td>\n      <td>0.359894</td>\n      <td>-0.358091</td>\n      <td>-0.137134</td>\n      <td>0.517617</td>\n      <td>0.401726</td>\n      <td>-0.058133</td>\n      <td>0.068653</td>\n      <td>-0.033194</td>\n      <td>0.084968</td>\n      <td>-0.208254</td>\n      <td>-0.559825</td>\n      <td>-0.026398</td>\n      <td>-0.371427</td>\n      <td>-0.232794</td>\n      <td>0.105915</td>\n      <td>0.253844</td>\n      <td>0.081080</td>\n      <td>3.67</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>4.0</td>\n      <td>1.229658</td>\n      <td>0.141004</td>\n      <td>0.045371</td>\n      <td>1.202613</td>\n      <td>0.191881</td>\n      <td>0.272708</td>\n      <td>-0.005159</td>\n      <td>0.081213</td>\n      <td>0.464960</td>\n      <td>-0.099254</td>\n      <td>-1.416907</td>\n      <td>-0.153826</td>\n      <td>-0.751063</td>\n      <td>0.167372</td>\n      <td>0.050144</td>\n      <td>-0.443587</td>\n      <td>0.002821</td>\n      <td>-0.611987</td>\n      <td>-0.045575</td>\n      <td>-0.219633</td>\n      <td>-0.167716</td>\n      <td>-0.270710</td>\n      <td>-0.154104</td>\n      <td>-0.780055</td>\n      <td>0.750137</td>\n      <td>-0.257237</td>\n      <td>0.034507</td>\n      <td>0.005168</td>\n      <td>4.99</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.0</td>\n      <td>-0.644269</td>\n      <td>1.417964</td>\n      <td>1.074380</td>\n      <td>-0.492199</td>\n      <td>0.948934</td>\n      <td>0.428118</td>\n      <td>1.120631</td>\n      <td>-3.807864</td>\n      <td>0.615375</td>\n      <td>1.249376</td>\n      <td>-0.619468</td>\n      <td>0.291474</td>\n      <td>1.757964</td>\n      <td>-1.323865</td>\n      <td>0.686133</td>\n      <td>-0.076127</td>\n      <td>-1.222127</td>\n      <td>-0.358222</td>\n      <td>0.324505</td>\n      <td>-0.156742</td>\n      <td>1.943465</td>\n      <td>-1.015455</td>\n      <td>0.057504</td>\n      <td>-0.649709</td>\n      <td>-0.415267</td>\n      <td>-0.051634</td>\n      <td>-1.206921</td>\n      <td>-1.085339</td>\n      <td>40.80</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>7.0</td>\n      <td>-0.894286</td>\n      <td>0.286157</td>\n      <td>-0.113192</td>\n      <td>-0.271526</td>\n      <td>2.669599</td>\n      <td>3.721818</td>\n      <td>0.370145</td>\n      <td>0.851084</td>\n      <td>-0.392048</td>\n      <td>-0.410430</td>\n      <td>-0.705117</td>\n      <td>-0.110452</td>\n      <td>-0.286254</td>\n      <td>0.074355</td>\n      <td>-0.328783</td>\n      <td>-0.210077</td>\n      <td>-0.499768</td>\n      <td>0.118765</td>\n      <td>0.570328</td>\n      <td>0.052736</td>\n      <td>-0.073425</td>\n      <td>-0.268092</td>\n      <td>-0.204233</td>\n      <td>1.011592</td>\n      <td>0.373205</td>\n      <td>-0.384157</td>\n      <td>0.011747</td>\n      <td>0.142404</td>\n      <td>93.20</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9.0</td>\n      <td>-0.338262</td>\n      <td>1.119593</td>\n      <td>1.044367</td>\n      <td>-0.222187</td>\n      <td>0.499361</td>\n      <td>-0.246761</td>\n      <td>0.651583</td>\n      <td>0.069539</td>\n      <td>-0.736727</td>\n      <td>-0.366846</td>\n      <td>1.017614</td>\n      <td>0.836390</td>\n      <td>1.006844</td>\n      <td>-0.443523</td>\n      <td>0.150219</td>\n      <td>0.739453</td>\n      <td>-0.540980</td>\n      <td>0.476677</td>\n      <td>0.451773</td>\n      <td>0.203711</td>\n      <td>-0.246914</td>\n      <td>-0.633753</td>\n      <td>-0.120794</td>\n      <td>-0.385050</td>\n      <td>-0.069733</td>\n      <td>0.094199</td>\n      <td>0.246219</td>\n      <td>0.083076</td>\n      <td>3.68</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9       V10       V11       V12       V13       V14  \\\n0  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169   \n1  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772   \n2  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946   \n3  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924   \n4 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670   \n\n        V15       V16       V17       V18       V19       V20       V21  \\\n0  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307   \n1  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775   \n2  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998   \n3 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300   \n4  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431   \n\n        V22       V23       V24       V25       V26       V27       V28  \\\n0  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n1 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n2  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n3  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n4  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n\n   Amount  \n0  149.62  \n1    2.69  \n2  378.66  \n3  123.50  \n4   69.99  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>V10</th>\n      <th>V11</th>\n      <th>V12</th>\n      <th>V13</th>\n      <th>V14</th>\n      <th>V15</th>\n      <th>V16</th>\n      <th>V17</th>\n      <th>V18</th>\n      <th>V19</th>\n      <th>V20</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>0.090794</td>\n      <td>-0.551600</td>\n      <td>-0.617801</td>\n      <td>-0.991390</td>\n      <td>-0.311169</td>\n      <td>1.468177</td>\n      <td>-0.470401</td>\n      <td>0.207971</td>\n      <td>0.025791</td>\n      <td>0.403993</td>\n      <td>0.251412</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>-0.166974</td>\n      <td>1.612727</td>\n      <td>1.065235</td>\n      <td>0.489095</td>\n      <td>-0.143772</td>\n      <td>0.635558</td>\n      <td>0.463917</td>\n      <td>-0.114805</td>\n      <td>-0.183361</td>\n      <td>-0.145783</td>\n      <td>-0.069083</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>0.207643</td>\n      <td>0.624501</td>\n      <td>0.066084</td>\n      <td>0.717293</td>\n      <td>-0.165946</td>\n      <td>2.345865</td>\n      <td>-2.890083</td>\n      <td>1.109969</td>\n      <td>-0.121359</td>\n      <td>-2.261857</td>\n      <td>0.524980</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>-0.054952</td>\n      <td>-0.226487</td>\n      <td>0.178228</td>\n      <td>0.507757</td>\n      <td>-0.287924</td>\n      <td>-0.631418</td>\n      <td>-1.059647</td>\n      <td>-0.684093</td>\n      <td>1.965775</td>\n      <td>-1.232622</td>\n      <td>-0.208038</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>0.753074</td>\n      <td>-0.822843</td>\n      <td>0.538196</td>\n      <td>1.345852</td>\n      <td>-1.119670</td>\n      <td>0.175121</td>\n      <td>-0.451449</td>\n      <td>-0.237033</td>\n      <td>-0.038195</td>\n      <td>0.803487</td>\n      <td>0.408542</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(\"Class\", axis=1)\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0\n1    0\n2    0\n3    0\n4    0\nName: Class, dtype: int64"
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[\"Class\"]\n",
    "y.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "((199364, 30), (85443, 30), (199364,), (85443,))"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], 'max_features': np.arange(3, 5), 'max_depth': np.arange(4, 7)}]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "gscv = GridSearchCV(estimator=RandomForestClassifier(random_state=100), param_grid=parameters,\n",
    "                   scoring='roc_auc',\n",
    "                   cv=3,\n",
    "                   )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=100),\n             param_grid=[{'max_depth': array([4, 5, 6]),\n                          'max_features': array([3, 4]),\n                          'n_estimators': [10, 15]}],\n             scoring='roc_auc')"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "{'max_depth': 6, 'max_features': 3, 'n_estimators': 15}"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_params_"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99070828e-01 9.29171738e-04]\n",
      " [9.99704794e-01 2.95206364e-04]\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " [9.99717846e-01 2.82154033e-04]\n",
      " [9.99717846e-01 2.82154033e-04]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = gscv.predict_proba(X_test)\n",
    "print(y_pred_proba[:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00092917 0.00029521 0.00028215 0.00028215 0.00028215]\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = y_pred_proba[:, 1]\n",
    "print(y_pred_proba[:5])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9462664156037156"
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
